{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Experiments\n",
    "\n",
    "Simulation code for running the numerical experiments reported in the paper:  \n",
    "**Vidit Saxena and Joakim JaldÃ©n,\"Bayesian Link Adaptation under a BLER Target\", In 2020 IEEE 21st International Workshop on Signal Processing Advances in Wireless Communications (SPAWC) on May 26-29, 2020.** \n",
    "\n",
    "This simulation code is written in Python3. Running each of the subsequent cells in sequence will execute the experiments and generate a results file (in .npy format) that is saved to the disk.\n",
    "\n",
    "The simulations make extensive use of the [py-itpp](https://github.com/vidits-kth/py-itpp), [Numpy](https://github.com/numpy/numpy), and [Matplotlib](https://github.com/matplotlib/matplotlib) packages.\n",
    "\n",
    "Additionally, to speed up the generation of results, the simulations are parallezlized using the [Ray](http://ray.readthedocs.io/en/latest/index.html) package. It is possible to run single-threaded simulations at the cost of slowness, by commenting out the Ray-specific lines in the notebook - this is indicated in the appropriate sections of the code.\n",
    "\n",
    "The user-defined parameters are highlighted with the USER-DEFINED tag below; set these values below to setup and run the experiments for the desired parameters."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import ray\n",
    "import time\n",
    "\n",
    "from src.environment import simulate_rayleigh_fading_channel\n",
    "from src.link_adaptation_agents import TrackingThompsonSamplingBandit, ThompsonSamplingBandit, OuterLoopLinkAdaptation, DiscountThompsonSamplingBandit\n",
    "\n",
    "plt.rcParams.update({'font.size': 22, 'lines.linewidth' : 3})\n",
    "\n",
    "# RAY: If Ray is installed on this machine, initialize it properly below. \n",
    "# It is also possible to run the experiments without Ray. In that case, comment out the lines below and in \n",
    "# subsequent cells, where identified with the RAY: comment.\n",
    "# ray_redis_address = \"10.0.0.5:15672\"\n",
    "# ray.init(address=ray_redis_address, ignore_reinit_error=True, log_to_driver=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load SNR-to-CQI Lookup Data\n",
    "The CQI values are calculated using an offline lookup table of AWGN BLER values. For a complete description of the CQI generation technique, refer to [11] referenced in the pabler. This lookup data is used for AMC part of the AMC-OLLA technique.\n",
    "\n",
    "The AWGN_DATASET is generated offline using a separate simulation (not reported here since it is not relevant to this pabler). This dataset contains the measured BLER for a large range of average SNRs, for each of the MCSs simulated in this pabler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awgn_datafile = 'AWGN_DATASET.npy'\n",
    "awgn_data = np.load( awgn_datafile, allow_pickle=True )[ ( ) ]\n",
    "\n",
    "snr_vs_bler = awgn_data['snr_vs_per']\n",
    "snr_range_dB = awgn_data['snr_range_dB']\n",
    "\n",
    "nrof_snr, nrof_rates = snr_vs_bler.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the lookup data\n",
    "plt.figure(figsize=[20,5])\n",
    "\n",
    "legend = []\n",
    "for i in range( nrof_rates ):\n",
    "    plt.semilogy( snr_range_dB, snr_vs_bler[:,i] )\n",
    "    legend.append('MCS %d'%(i))\n",
    "    \n",
    "plt.legend(legend, ncol=2)\n",
    "plt.title('SNR-vs-BLER data for CQI lookup')\n",
    "plt.xlabel('Average SNR [dB]')\n",
    "plt.ylabel('BLER')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard-defined transport block sizes from [12, Tab. 7.1.7.2.1-1]\n",
    "packet_sizes = [152, 200, 248, 320, 408, 504, 600, 712, 808, 936, \n",
    "                936, 1032, 1192, 1352, 1544, 1736, 1800, \n",
    "                1800, 1928, 2152, 2344, 2600, 2792, 2984, 3240, 3496, 3624, 3752, 4008]\n",
    "\n",
    "# Standard-defined Modulation orders from [12, Tab. 7.1.7.1-1]\n",
    "modorders    = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, \n",
    "                4, 4, 4, 4, 4, 4, 4, \n",
    "                6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
    "\n",
    "# USER-DEFINED target BLER and OLLA parameters\n",
    "target_bler = 0.1\n",
    "olla_step_size = 0.1\n",
    "\n",
    "# USER-DEFINED wireless channel configuration\n",
    "norm_doppler = 0.01\n",
    "avg_snr_dB = 15\n",
    "\n",
    "# USER-DEFINED exbleriment parameters\n",
    "# nrof_ttis = 50\n",
    "# nrof_experiments = 10\n",
    "nrof_ttis = 1000\n",
    "nrof_experiments = 5\n",
    "\n",
    "# Parameter settings for Figs. 1(a) and 1(b) in the paper:\n",
    "#target_bler = 0.1\n",
    "olla_step_size = 0.1\n",
    "norm_doppler = 0.01\n",
    "avg_snr_dB = 15\n",
    "# nrof_ttis = 5000\n",
    "# nrof_experiments = 1000\n",
    "\n",
    "# Parameter settings for Figs. 1(c) and 1(d) in the paper:\n",
    "#target_bler = 0.3\n",
    "# olla_step_size = 0.1\n",
    "# norm_doppler = 0.01\n",
    "# avg_snr_dB = 15\n",
    "# nrof_ttis = 5000\n",
    "# nrof_experiments = 1000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract prior BLER corresponding to each CQI value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.channel_quality_index import estimate_sinr_from_cqi, determine_bler_at_sinr\n",
    "\n",
    "nrof_cqi = 16\n",
    "bler_bler_cqi = np.ndarray( ( len( packet_sizes ), nrof_cqi ) )\n",
    "for cqi in range( nrof_cqi ):\n",
    "    snr_dB = estimate_sinr_from_cqi(cqi, awgn_data)\n",
    "    bler_bler_cqi[ :, cqi ] = determine_bler_at_sinr(snr_dB, awgn_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLLA and BaysLA for link adaptation over a Rayleigh Fading channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAY: The following method is packaged using Ray. To remove this dependence, comment out the line below.\n",
    "# @ray.remote  # Comment this out if Ray is not used\n",
    "def run_experiment( seed, nrof_ttis, avg_snr_dB, target_bler, olla_step_size, norm_doppler ):\n",
    "    # pieces = 500\n",
    "    # pieces = 10\n",
    "    # piece_len = nrof_ttis // pieces\n",
    "    \n",
    "    #print('piece_len:' + piece_len)\n",
    "    # error_stationary, cqi_stationary = simluate_rayleigh_fading_channel(nrof_ttis, \n",
    "    packet_error_probabilities, channel_quality_indices = simulate_rayleigh_fading_channel(nrof_ttis, \n",
    "                                                                        avg_snr_dB, \n",
    "                                                                        awgn_data, \n",
    "                                                                        packet_sizes, \n",
    "                                                                        norm_doppler,\n",
    "                                                                        seed=seed)\n",
    "    # error, CQI = simluate_rayleigh_fading_channel(piece_len, avg_snr_dB, awgn_data, packet_sizes, norm_doppler,\n",
    "    #                                               seed=seed)\n",
    "    # packet_error_probabilities = error\n",
    "    # channel_quality_indices = CQI\n",
    "    # for piece in range(1, pieces):\n",
    "    #     avg_snr_dB = np.random.randint(5,30)\n",
    "    #     norm_doppler = np.random.uniform(0, 0.5)\n",
    "    #     error, CQI = simluate_rayleigh_fading_channel( piece_len, \n",
    "    #                                                   avg_snr_dB, \n",
    "    #                                                   awgn_data, \n",
    "    #                                                   packet_sizes, \n",
    "    #                                                   norm_doppler, \n",
    "    #                                                   seed = seed )\n",
    "\n",
    "    #     packet_error_probabilities = np.vstack((packet_error_probabilities, error))\n",
    "    #     channel_quality_indices = np.hstack((channel_quality_indices, CQI))\n",
    "      \n",
    "    #    print(\"SNR:%.2f\"%avg_snr_dB)\n",
    "    #    print(\"Doppler:%.2f\"%norm_doppler)\n",
    "\n",
    "#     # Visualize the packet error probabilities\n",
    "#     plt.figure(figsize=[20,5])\n",
    "\n",
    "#     legend = []\n",
    "#     for i in range( nrof_rates ):\n",
    "#         plt(packet_error_probabilities[:,i] )\n",
    "#         legend.append('MCS %d'%(i))\n",
    "    \n",
    "#     plt.legend(legend, ncol=2)\n",
    "#     plt.xlabel('t')\n",
    "#     plt.ylabel('packet error probabilities')\n",
    "    \n",
    "#     # Visualize the channel quality indices\n",
    "#     plt.figure(figsize=[20,5])\n",
    "\n",
    "#     legend = []\n",
    "#     for i in range( nrof_rates ):\n",
    "#         plt(channel_quality_indices[:,i] )\n",
    "#         legend.append('MCS %d'%(i))\n",
    "    \n",
    "#     plt.legend(legend, ncol=2)\n",
    "#     plt.xlabel('t')\n",
    "#     plt.ylabel('channel quality indices')\n",
    "    \n",
    "    # Pre-generate ACK events for all rates for all channel samples\n",
    "    packet_acks = np.ndarray( ( nrof_ttis, nrof_rates ) )\n",
    "    for tti in range( nrof_ttis ):\n",
    "        for rate_index in range( nrof_rates ):\n",
    "            packet_acks[tti, rate_index] = np.random.uniform( ) > packet_error_probabilities[tti, rate_index]\n",
    "\n",
    "    # Outer Loop Link Adaptation\n",
    "    olla_bandit = OuterLoopLinkAdaptation(nrof_rates, nrof_cqi, packet_sizes, awgn_data, target_bler, olla_step_size)\n",
    "    \n",
    "    cqi_delay = 0 \n",
    "    \n",
    "    olla_rates  = []\n",
    "    olla_acks  = []\n",
    "    olla_tputs = []\n",
    "    for tti in range( nrof_ttis ):\n",
    "        \n",
    "        # Skip the first few samples to account for CQI delay\n",
    "        if tti < cqi_delay:\n",
    "            selected_rate_index = np.random.randint(0, nrof_cqi)\n",
    "            ack = packet_acks[tti, selected_rate_index]\n",
    "        else:  \n",
    "            cqi = channel_quality_indices[tti - cqi_delay]    \n",
    "            selected_rate_index = olla_bandit.act( cqi )\n",
    "\n",
    "            ack = packet_acks[tti, selected_rate_index]\n",
    "            olla_bandit.update( selected_rate_index, cqi, ack )\n",
    "\n",
    "        olla_rates.append(selected_rate_index)\n",
    "        olla_acks.append(ack)\n",
    "        olla_tputs.append( packet_sizes[ selected_rate_index ] * ack )\n",
    "    \n",
    "    # Thompson Sampling with Informed Priors\n",
    "    bayesla_bandit = ThompsonSamplingBandit(nrof_rates, nrof_cqi, packet_sizes, target_bler, bler_bler_cqi)\n",
    "    \n",
    "    bayesla_rates  = []\n",
    "    bayesla_acks  = []\n",
    "    bayesla_tputs = []\n",
    "    for tti in range( nrof_ttis ):\n",
    "        \n",
    "        # Skip the first few samples to account for CQI delay\n",
    "        if tti < cqi_delay:\n",
    "            selected_rate_index = np.random.randint(0, nrof_cqi)\n",
    "            ack = packet_acks[tti, selected_rate_index]\n",
    "        else:    \n",
    "            cqi = channel_quality_indices[tti - cqi_delay]    \n",
    "            selected_rate_index = bayesla_bandit.act( cqi )\n",
    "\n",
    "            ack = packet_acks[tti, selected_rate_index]\n",
    "            bayesla_bandit.update( selected_rate_index, cqi, ack )\n",
    "\n",
    "        bayesla_rates.append(selected_rate_index)\n",
    "        bayesla_acks.append(ack)\n",
    "        bayesla_tputs.append( packet_sizes[ selected_rate_index ] * ack )\n",
    "    \n",
    "#     return ( olla_rates, olla_acks, olla_tputs, \n",
    "#              bayesla_rates, bayesla_acks, bayesla_tputs, )\n",
    "\n",
    "\n",
    "    # Tracking Thompson Sampling\n",
    "    Trackbayesla_bandit = TrackingThompsonSamplingBandit(nrof_rates, nrof_cqi,packet_sizes, target_bler, bler_bler_cqi)\n",
    "    Trackbayesla_bandit.discount = 0.25\n",
    "    \n",
    "    Trackbayesla_rates  = []\n",
    "    Trackbayesla_acks  = []\n",
    "    Trackbayesla_tputs = []\n",
    "    for tti in range( nrof_ttis ):\n",
    "        \n",
    "        # Skip the first few samples to account for CQI delay\n",
    "        if tti < cqi_delay:\n",
    "            selected_rate_index = np.random.randint(0, nrof_cqi)\n",
    "            ack = packet_acks[tti, selected_rate_index]\n",
    "        else:    \n",
    "            cqi = channel_quality_indices[tti - cqi_delay]    \n",
    "            selected_rate_index = Trackbayesla_bandit.act( cqi )\n",
    "\n",
    "            ack = packet_acks[tti, selected_rate_index]\n",
    "            Trackbayesla_bandit.update( selected_rate_index, cqi, ack )\n",
    "\n",
    "        Trackbayesla_rates.append(selected_rate_index)\n",
    "        Trackbayesla_acks.append(ack)\n",
    "        Trackbayesla_tputs.append( packet_sizes[ selected_rate_index ] * ack )\n",
    "    \n",
    "    \n",
    "    # 20230530: added dTS for testing\n",
    "    # actually dTS (discounted Thompson Sampling)\n",
    "    dts_bandit = DiscountThompsonSamplingBandit(nrof_rates, packet_sizes, discount=0.75)\n",
    "    \n",
    "    dts_rates  = []\n",
    "    dts_acks  = []\n",
    "    dts_tputs = []\n",
    "    for tti in range( nrof_ttis ):\n",
    "        # Skip the first few samples to account for CQI delay\n",
    "        if tti < cqi_delay:\n",
    "            selected_rate_index = np.random.randint(0, nrof_cqi)\n",
    "            ack = packet_acks[tti, selected_rate_index]\n",
    "        else:    \n",
    "            selected_rate_index = dts_bandit.act()\n",
    "\n",
    "            ack = packet_acks[tti, selected_rate_index]\n",
    "            dts_bandit.update( selected_rate_index, 0, ack ) # dummy cqi=0\n",
    "\n",
    "        dts_rates.append(selected_rate_index)\n",
    "        dts_acks.append(ack)\n",
    "        dts_tputs.append( packet_sizes[ selected_rate_index ] * ack )\n",
    "    \n",
    "    return ( olla_rates, olla_acks, olla_tputs, \n",
    "             bayesla_rates, bayesla_acks, bayesla_tputs, \n",
    "             Trackbayesla_rates, Trackbayesla_acks, Trackbayesla_tputs, \n",
    "             dts_rates, dts_acks, dts_tputs,\n",
    "             packet_error_probabilities, channel_quality_indices)\n",
    "            #  error_stationary, cqi_stationary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the experiments and collect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "olla_mcs = []\n",
    "olla_ack = []\n",
    "olla_tput = []\n",
    "\n",
    "bayesla_mcs = []\n",
    "bayesla_ack = []\n",
    "bayesla_tput = []\n",
    "\n",
    "Trackbayesla_mcs = []\n",
    "Trackbayesla_ack = []\n",
    "Trackbayesla_tput = []\n",
    "\n",
    "dts_mcs = []\n",
    "dts_ack = []\n",
    "dts_tput = []\n",
    "\n",
    "# RAY: The following line runs the Ray-packaged method. To avoid using Ray, comment out the next line and uncomment\n",
    "# the line that immediately follows it in order to run the experiments.\n",
    "# results = ray.get( [ run_experiment.remote( i,\n",
    "#                                             nrof_ttis, \n",
    "#                                             avg_snr_dB, \n",
    "#                                             target_bler,\n",
    "#                                             olla_step_size,\n",
    "#                                             norm_doppler ) for i in range(nrof_experiments) ] )\n",
    "\n",
    "# RAY: uncomment the next line to run a single-threaded simulation that does not depend on Ray.\n",
    "results = [ run_experiment( i, nrof_ttis, avg_snr_dB, target_bler, olla_step_size, norm_doppler ) for i in range(nrof_experiments) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(results[8]))\n",
    "# print(len(bayesla_mcs))\n",
    "# print(len(Trackbayesla_tput))\n",
    "# print(len(packet_error_probabilities))\n",
    "# print(len(channel_quality_indices))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the results in separate variables for OLLA and BayesLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in results:\n",
    "    olla_mcs.append( res[0] )\n",
    "    olla_ack.append( res[1] )\n",
    "    olla_tput.append( res[2] )\n",
    "    \n",
    "    bayesla_mcs.append( res[3] )\n",
    "    bayesla_ack.append( res[4] )\n",
    "    bayesla_tput.append( res[5] )\n",
    "    \n",
    "    Trackbayesla_mcs.append( res[6] )\n",
    "    Trackbayesla_ack.append( res[7] )\n",
    "    Trackbayesla_tput.append( res[8] )\n",
    "    \n",
    "    dts_mcs.append( res[9] )\n",
    "    dts_ack.append( res[10] )\n",
    "    dts_tput.append( res[11] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(snr_vs_bler[:,1]))\n",
    "# print(snr_vs_bler[:,1].size)\n",
    "# print(type(snr_range_dB))\n",
    "# print(snr_range_dB.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "packet_error_probabilities = res[-4]\n",
    "channel_quality_indices = res[-3]\n",
    "error_stationary = res[-2]\n",
    "cqi_stationary = res[-1]\n",
    "# print(type(packet_error_probabilities[:,1]))\n",
    "# print(packet_error_probabilities[:,1].size)\n",
    "# list_error = packet_error_probabilities.tolist()\n",
    "# list_cqi = channel_quality_indices.tolist()\n",
    "# print(np.shape(list_error))\n",
    "\n",
    "# Visualize the packet error probabilities\n",
    "\n",
    "time_horizon = range(1, nrof_ttis + 1)\n",
    "time_horizon = np.array(time_horizon)\n",
    "\n",
    "plt.figure(figsize=[20,5])\n",
    "# plt.plot(time_horizon, packet_error_probabilities[:,20])\n",
    "plt.plot(time_horizon, packet_error_probabilities[:])\n",
    "#plt.plot(time_horizon, error_stationary[:,20])\n",
    "\n",
    "# legend = []\n",
    "# for i in range( nrof_rates ):\n",
    "#     plt.plot(time_horizon, packet_error_probabilities[:,i])\n",
    "#     legend.append('MCS %d'%(i))    \n",
    "# plt.legend(legend, ncol=2)\n",
    "\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('packet error probabilities')\n",
    "    \n",
    "# Visualize the channel quality indices\n",
    "plt.figure(figsize=[20,5])\n",
    "\n",
    "plt.plot(time_horizon, channel_quality_indices)\n",
    "# plt.plot(time_horizon, cqi_stationary)\n",
    "\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('channel quality indices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(packet_error_probabilities, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_prob = np.unique(packet_error_probabilities, return_counts=True)\n",
    "# plt.hist(x=hist_prob[1], bins=hist_prob[0])\n",
    "counts, bins = np.histogram(packet_error_probabilities, 50)\n",
    "# plt.stairs(counts, bins)\n",
    "width = 0.7 * (bins[1] - bins[0])\n",
    "\n",
    "center = (bins[:-1] + bins[1:]) / 2\n",
    "plt.bar(center, counts, width=width)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the results to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= { 'olla': ([], olla_ack, olla_tput),\n",
    "        'bayesla': ([], bayesla_ack, bayesla_tput),\n",
    "        'Trackbayesla': ([], Trackbayesla_ack, Trackbayesla_tput),\n",
    "        'dts': ([], dts_ack, dts_tput)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_file = 'RESULT_SNR_%d_TARGET_%0.1f_DELAY_%d.npy'%( avg_snr_dB, target_bler, cqi_delay)\n",
    "\n",
    "result_file = 'TEST_wei_nonstationary.npy'\n",
    "\n",
    "np.save(result_file, data)\n",
    "\n",
    "print('Saved to %s'%(result_file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
